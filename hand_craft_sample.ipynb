{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/NTU_ML/blob/Hw5/hand_craft_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "OC_P8bFMzILD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.optim import SGD, Adam, AdamW\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.datasets import make_classification\n",
        "seed = 3047\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1o0m3jyfmetUOJ146TqHuEGUWwQyC7JXV\n",
        "!gdown 1B5OC3R0yM8F7yjoYOKu3t08QZalcr7DC\n",
        "!gdown 1THvOuf_EOn6c_6TLy0Bqs23BP2NraBR2"
      ],
      "metadata": {
        "id": "FucrkOKI3m_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SVM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SVM, self).__init__()\n",
        "\n",
        "        self.w = nn.Parameter(torch.randn((4, 1)).to(torch.float32))\n",
        "        self._gamma = torch.nn.Parameter(torch.FloatTensor([1]),\n",
        "                                         requires_grad = True)\n",
        "\n",
        "        #define kernal & feature selection\n",
        "        self.f = nn.Sequential(\n",
        "                  nn.Linear(107, 4),\n",
        "                  )\n",
        "\n",
        "    def kernel(self, x):\n",
        "        x = self.f(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = torch.matmul(self.kernel(x), self.w)\n",
        "        return f"
      ],
      "metadata": {
        "id": "Iywj8wLF8ppU"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HingeLoss(nn.Module):\n",
        "  def __init__(self, C):\n",
        "    super(HingeLoss, self).__init__()\n",
        "    self.C = C\n",
        "\n",
        "  def forward(self, y, f):\n",
        "    loss = torch.sum(self.C * nn.functional.relu(1 - y * f)) / y.shape[0]\n",
        "    return loss"
      ],
      "metadata": {
        "id": "X2a0522z7IWo"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "  def __init__(self,split, mu=None, std=None):\n",
        "\n",
        "    X = pd.read_csv(f\"{split}.csv\")\n",
        "\n",
        "\n",
        "    X_c = X[['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']].values\n",
        "    X_d = X.drop(['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss', 'y'], 1).values\n",
        "    Y = X['y'].values.reshape(-1) * 2 - 1   #1 or -1\n",
        "\n",
        "    X_c, mu, std = self.normalize(X_c, mu, std)\n",
        "\n",
        "    X = np.concatenate((X_d, X_c, np.ones((X.shape[0], 1))), 1)\n",
        "    self.Y = torch.from_numpy(Y).to(torch.float32)\n",
        "    self.X = torch.from_numpy(X).to(torch.float32)\n",
        "    self.mu = mu\n",
        "    self.std = std\n",
        "\n",
        "  def normalize(self, X, mu=None, std=None):\n",
        "    #ToDo\n",
        "    mu = np.mean(X.astype('float64') , axis = 0)\n",
        "    std = np.std(X.astype('float64') , axis = 0)\n",
        "    mu[3:5] = ([1e-10,1e-10])\n",
        "    std[3:5] = ([1,1])\n",
        "    X = (X - mu) / (std + 1e-10)\n",
        "\n",
        "    return X, mu, std\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.size(0)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.Y[idx]"
      ],
      "metadata": {
        "id": "iBTrbIzE_AI9"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "  def __init__(self, mu, std):\n",
        "    X = pd.read_csv(\"X_test\")\n",
        "    X_c = X[['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']].values\n",
        "    X_d = X.drop(['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss'], 1).values\n",
        "    X_c= self.normalize(X_c, mu, std)\n",
        "    X = np.concatenate((X_d, X_c, np.ones((X.shape[0], 1))), 1)\n",
        "    self.X = torch.from_numpy(X).to(torch.float32)\n",
        "\n",
        "  def normalize(self, X, mu_x, std_x):\n",
        "    X = (X - mu_x) / (std_x + 1e-10)\n",
        "\n",
        "    return X\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.size(0)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx]"
      ],
      "metadata": {
        "id": "zeH2Lf-h_8sC"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_data, val_data, model, optim, C, device='cuda:0'):\n",
        "    epoch = 100\n",
        "    objective = HingeLoss(C)\n",
        "    steps = 0\n",
        "    best = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "      for tr in train_data:\n",
        "        steps += 1\n",
        "        x_train, y_train = tr\n",
        "        x_train, y_train = x_train.to(device), y_train.to(device)\n",
        "\n",
        "        # TODO : try to implement gradient descent\n",
        "        pred = model(x_train)\n",
        "        loss = objective(pred, y_train)\n",
        "\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "\n",
        "        if steps % 100 == 0:\n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "            acc = []\n",
        "            for val in val_data:\n",
        "              x_val, y_val = val\n",
        "              x_val , y_val = x_val.to(device), y_val.to(device)\n",
        "              pred = model(x_val).squeeze(1)\n",
        "              pred = (pred > 0) * 2 - 1\n",
        "\n",
        "              result = (y_val == pred)\n",
        "              acc += [(float(result.sum()) / result.size(0))]\n",
        "            acc = sum(acc) / len(acc)\n",
        "            print(f'Steps {steps}| Train Loss = {loss.item()}| Val acc = {acc}')\n",
        "\n",
        "            if acc > best:\n",
        "              torch.save(model.state_dict(), 'best.ckpt')\n",
        "              print(\"**************************************\")\n",
        "              best = acc\n",
        "          model.train()\n",
        "    return model"
      ],
      "metadata": {
        "id": "m5PZP044Pxuu"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001\n",
        "batch = 2048\n",
        "C = 100\n",
        "device = 'cuda:0'"
      ],
      "metadata": {
        "id": "ucnbZEiVPia3"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = TrainDataset('train')\n",
        "devset = TrainDataset('val', trainset.mu, trainset.std)\n",
        "testset = TestDataset(trainset.mu, trainset.std)\n",
        "\n",
        "train_dataloader = DataLoader(trainset, batch, True, drop_last=False)\n",
        "val_dataloader = DataLoader(devset, 1, False)\n",
        "test_dataloader = DataLoader(testset, 1, False)\n",
        "\n",
        "model = SVM().to(device)\n",
        "optim = Adam(model.parameters(), lr)\n",
        "model = train(train_dataloader, val_dataloader, model, optim, C, device)"
      ],
      "metadata": {
        "id": "YF1QyZXG4eI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = model\n",
        "best_model.load_state_dict(torch.load('best.ckpt'))\n",
        "best_model = best_model.eval()\n",
        "# TODO: predict x_test\n",
        "y_test = []\n",
        "for x in test_dataloader:\n",
        "  x = x.to(device)\n",
        "  y = best_model(x)\n",
        "  y_test.append(((y > 0) * 1).item())\n",
        "\n"
      ],
      "metadata": {
        "id": "42J0DE2DQQ8u"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('predict.csv', 'w', newline='') as csvf:\n",
        "    # 建立 CSV 檔寫入器\n",
        "    writer = csv.writer(csvf)\n",
        "    writer.writerow(['id','label'])\n",
        "    for i in range(len(y_test)):\n",
        "      writer.writerow( [i + 1, int(y_test[i])] )"
      ],
      "metadata": {
        "id": "sYJnjxOiQKqB"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUQ7Dqi-AhoB"
      },
      "execution_count": 164,
      "outputs": []
    }
  ]
}