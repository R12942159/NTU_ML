{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/NTU_ML/blob/Hw3/hw3_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bChr_H2yYT8I"
      },
      "source": [
        "# Import Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haDwKU5XYT8N"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "\n",
        "# other library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# PyTorch library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fix random seed"
      ],
      "metadata": {
        "id": "fpvte-jiKPIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 5566 # Do not modify\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "qB1CAe7AKLkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Download:"
      ],
      "metadata": {
        "id": "SsElVXQcG5LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id \"1Rlt_mU-siC6AayAjNMXZ8N8fURWg5iLB\" --output \"trainX.npy\"\n",
        "!gdown --id \"1v7i5rP2UQv_2ju8akh69M5VzEjRJV3tB\" --output \"visualization_X.npy\"\n"
      ],
      "metadata": {
        "id": "F6TAIp_9G25H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8935f1-a51e-43e9-d45e-236fec802845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Rlt_mU-siC6AayAjNMXZ8N8fURWg5iLB\n",
            "To: /content/trainX.npy\n",
            "100% 221M/221M [00:05<00:00, 40.9MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1v7i5rP2UQv_2ju8akh69M5VzEjRJV3tB\n",
            "To: /content/visualization_X.npy\n",
            "100% 15.4M/15.4M [00:00<00:00, 21.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrKJU3sEYT8P"
      },
      "source": [
        "# Set Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkdXQ__LYT8Q"
      },
      "outputs": [],
      "source": [
        "#TODO: Modified the hyper-parameter\n",
        "NUM_EPOCH = 5\n",
        "BATCH_SIZE = 32\n",
        "LATENT_DIM = 32\n",
        "REDUCED_DIM = 8\n",
        "NUM_ITER = 1000\n",
        "REDUCED_METHOD = 'pca' # or 'tsne'\n",
        "lr = 5e-4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'model.pth'\n",
        "DATA_PATH = 'trainX.npy'"
      ],
      "metadata": {
        "id": "i8hEySbAKcrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxyzXIByYT8R"
      },
      "source": [
        "# Define Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2QgbyliYT8R"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.total_img = torch.from_numpy(np.load(data_path)).float()\n",
        "        self.total_img = self.total_img.permute(0, 3, 1, 2)\n",
        "        self.total_img = self.total_img/255\n",
        "\n",
        "    def normalize(self, img):\n",
        "        # TODO: normalize the dataset\n",
        "        return img\n",
        "\n",
        "    def augment(self, img):\n",
        "        # TODO: do augmentation while loading image\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.total_img)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.total_img[index]\n",
        "        img_aug = self.augment(img)\n",
        "\n",
        "        img_aug = self.normalize(img_aug)\n",
        "        img = self.normalize(img)\n",
        "        return img_aug, img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5JPY36vYT8S"
      },
      "source": [
        "# Define Model Architerchure\n",
        "\n",
        "**Please finish this block to run this code!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81Ai5AdWYT8T"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, image_channels=3, latent_dim=128):\n",
        "        super(Net, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_size = 32\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            # TODO: define your own structure\n",
        "        )\n",
        "\n",
        "        # TODO: check the dimension if you modified the structure\n",
        "        self.fc1 = nn.Linear(N, self.latent_dim)\n",
        "\n",
        "        # TODO: check the dimension if you modified the structure\n",
        "        self.fc2 = nn.Linear(self.latent_dim, N)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "           # TODO: define yout own structure\n",
        "           # Hint: nn.ConvTranspose2d(...)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        feature_map = self.encoder(x)\n",
        "        latent_vec = self.fc1(feature_map.reshape(feature_map.shape[0], -1))\n",
        "        feature_map2 = self.fc2(latent_vec)\n",
        "        x_res = self.decoder(feature_map2)\n",
        "\n",
        "        return latent_vec, x_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZJKXosgYT8T"
      },
      "source": [
        "# Define Training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDpDRuXTYT8U"
      },
      "outputs": [],
      "source": [
        "def training(train, val, model, device, n_epoch, batch, save_name, lr):\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print('=== start training, parameter total:%d, trainable:%d' % (total, trainable))\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
        "                             weight_decay=1e-5)\n",
        "    best_loss = 100\n",
        "    for epoch in range(n_epoch):\n",
        "        total_loss = 0\n",
        "\n",
        "        # training set\n",
        "        model.train()\n",
        "        idx = 0\n",
        "        for image_aug, image in tqdm(train):\n",
        "            image = image.to(device, dtype=torch.float)\n",
        "            image_aug = image_aug.to(device, dtype=torch.float)\n",
        "            _, reconsturct = model(image_aug)\n",
        "            loss = criterion(reconsturct, image)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += (loss.item() / len(train))\n",
        "\n",
        "            print('[Epoch %d | %d/%d] loss: %.4f' %\n",
        "                 ((epoch+1), idx*batch, len(train)*batch, loss.item()), end='\\r')\n",
        "            idx += 1\n",
        "        print(\"\\n  Training  | Loss:%.4f \" % total_loss)\n",
        "\n",
        "        # validation set\n",
        "        model.eval()\n",
        "        total_loss = 0\n",
        "        idx = 0\n",
        "        with torch.no_grad():\n",
        "            for image_aug, image in tqdm(val):\n",
        "                image = image.to(device, dtype=torch.float)\n",
        "                image_aug = image_aug.to(device, dtype=torch.float)\n",
        "                _, reconstruct = model(image_aug)\n",
        "\n",
        "                loss = criterion(reconstruct, image)\n",
        "                total_loss += (loss.item() / len(val))\n",
        "                idx += 1\n",
        "            print(\" Validation | Loss:%.4f \" % total_loss)\n",
        "        # save model\n",
        "        if total_loss < best_loss:\n",
        "                best_loss = total_loss\n",
        "                print(\"saving model with loss %.4f...\\n\" % total_loss)\n",
        "                torch.save(model.state_dict(), \"%s\" % save_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZG8CYmFYT8V"
      },
      "source": [
        "# Define Clustering Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20zxmIS_YT8V"
      },
      "outputs": [],
      "source": [
        "def clustering(model, device, loader, n_iter, reduced_method, reduced_dim, perplexity):\n",
        "    assert reduced_method in ['pca', 'tsne', None]\n",
        "\n",
        "    model.eval()\n",
        "    latent_vec = torch.tensor([]).to(device, dtype=torch.float)\n",
        "    for idx, (image_aug, image) in enumerate(loader):\n",
        "        print(\"predict %d / %d\" % (idx, len(loader)) , end='\\r')\n",
        "        image = image.to(device, dtype=torch.float)\n",
        "        latent, r = model(image)\n",
        "        latent_vec = torch.cat((latent_vec, latent), dim=0)\n",
        "\n",
        "    latent_vec = latent_vec.cpu().detach().numpy()\n",
        "\n",
        "    if reduced_method == 'tsne':\n",
        "        tsne = TSNE(n_components=reduced_dim, verbose=1, method='exact', perplexity=perplexity, n_iter=n_iter)\n",
        "        latent_vec = tsne.fit_transform(latent_vec)\n",
        "    elif reduced_method == 'pca':\n",
        "        pca = PCA(n_components=reduced_dim, copy=False, whiten=True, svd_solver='full')\n",
        "        latent_vec = pca.fit_transform(latent_vec)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=2, random_state=0, max_iter=n_iter).fit(latent_vec)\n",
        "    return kmeans.labels_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r5zzEzeYT8W"
      },
      "source": [
        "# Define write function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETN3MpfEYT8W"
      },
      "outputs": [],
      "source": [
        "def write_output(predict_result, file_name='predict.csv'):\n",
        "    with open(file_name, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['id', 'label'])\n",
        "        for i in range(len(predict_result)):\n",
        "            writer.writerow([str(i), str(predict_result[i])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM0EH4WLYT8W"
      },
      "source": [
        "# Main Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RICWirzhYT8X"
      },
      "outputs": [],
      "source": [
        "# build dataset\n",
        "dataset = Dataset(DATA_PATH)\n",
        "print(len(dataset))\n",
        "\n",
        "# Random split\n",
        "train_set_size = int(len(dataset) * 0.85)\n",
        "valid_set_size = len(dataset) - train_set_size\n",
        "train_set, valid_set = data.random_split(dataset, [train_set_size, valid_set_size])\n",
        "\n",
        "# set data loader\n",
        "train_loader = data.DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=1, shuffle=True)\n",
        "valid_loader = data.DataLoader(valid_set, batch_size=BATCH_SIZE, num_workers=1, shuffle=False)\n",
        "\n",
        "model = Net(latent_dim=LATENT_DIM).to(device)\n",
        "print(model)\n",
        "training(train_loader, valid_loader, model, device, NUM_EPOCH, BATCH_SIZE, MODEL_NAME, lr)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "hvqmT9dtHeeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "model.load_state_dict(torch.load(MODEL_NAME))\n",
        "predicted = clustering(model, device, test_loader, NUM_ITER, reduced_method=REDUCED_METHOD, reduced_dim=REDUCED_DIM, perplexity=15)\n",
        "write_output(predicted, 'pred.csv')"
      ],
      "metadata": {
        "id": "3CTaOA5ZHdSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}