{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/NTU_ML/blob/Hw3/EmbeddingV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMsNXtVLopQ2"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import csv\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "from torch.optim import Adam\n",
        "from torchvision import transforms as tr\n",
        "from torch.utils.data import DataLoader, Dataset, random_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c ml2023-fall-hw3\n",
        "!unzip 'ml2023-fall-hw3.zip'"
      ],
      "metadata": {
        "id": "P4wALECsmKsW",
        "outputId": "c9e19f3d-16c0-41af-a5ee-eb908c1a8266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6934a5e0-d264-42c4-846b-d44e7a817ecc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6934a5e0-d264-42c4-846b-d44e7a817ecc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading ml2023-fall-hw3.zip to /content\n",
            " 80% 41.0M/51.2M [00:00<00:00, 73.4MB/s]\n",
            "100% 51.2M/51.2M [00:00<00:00, 75.4MB/s]\n",
            "Archive:  ml2023-fall-hw3.zip\n",
            "  inflating: data/trainX.npy         \n",
            "  inflating: data/visualization_X.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdkZ1H4LwraP",
        "outputId": "4bf09e51-99d1-4dfa-e0a1-73750cf800cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using: {device}\")"
      ],
      "metadata": {
        "id": "UFLK8ywEhguj",
        "outputId": "b011f11b-710b-47f5-9c7b-5511e64182c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build Dataset and Dataloader"
      ],
      "metadata": {
        "id": "-KVCCUsz_d3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.load('/content/data/trainX.npy')[999] / 255.\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YsfdIQSeafTJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "936bdf4d-6adf-4beb-a927-cc405ad2542c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Hw3_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path: str, to_tensor, transform, augmentation=True) -> None:\n",
        "        self.all_data = np.load(data_path)\n",
        "        self.to_tensor = to_tensor\n",
        "        self.transform = transform\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "        hflip = tr.RandomHorizontalFlip(p=0.5)\n",
        "        vflip = tr.RandomVerticalFlip(p=0.5)\n",
        "        rotate = tr.RandomRotation(degrees=15)\n",
        "        color = tr.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
        "\n",
        "        def origine(x): return x\n",
        "        if augmentation:\n",
        "            self.augmentation = [hflip, vflip, rotate, origine]\n",
        "        else:\n",
        "            self.augmentation = [origine]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # read img\n",
        "        img = self.all_data[idx] # (3, 32, 32)\n",
        "\n",
        "        # to tensor type\n",
        "        img = self.to_tensor(img)\n",
        "        img /= 255.\n",
        "\n",
        "        # transform/normalize img\n",
        "        img_aug = self.transform(img)\n",
        "\n",
        "        # augmentation img\n",
        "        augment = random.choice(self.augmentation)\n",
        "        img_aug = augment(img_aug)\n",
        "        return img_aug, img"
      ],
      "metadata": {
        "id": "rjji7KijikOU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "img_ds = Hw3_dataset(\n",
        "    '/content/data/trainX.npy',\n",
        "    to_tensor = tr.Compose([\n",
        "        tr.ToTensor(),\n",
        "    ]),\n",
        "    transform = tr.Compose([\n",
        "        tr.Normalize(mean=mean, std=std),\n",
        "    ]),\n",
        "    augmentation = True,\n",
        ")"
      ],
      "metadata": {
        "id": "U0vcD84ssHtV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Randomly divided into a training and validation dataset."
      ],
      "metadata": {
        "id": "w3Fvnf6sAX6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_prob = 0.85\n",
        "\n",
        "train_size = int(len(img_ds) * train_prob)\n",
        "val_size = int(len(img_ds) - train_size)\n",
        "train_ds, val_ds = random_split(img_ds, [train_size, val_size])"
      ],
      "metadata": {
        "id": "43CrLsArvXUf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Build Dataloders"
      ],
      "metadata": {
        "id": "aA5GapINAVSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "IMG_SIZE = 32\n",
        "\n",
        "train_loader = DataLoader(train_ds, BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_ds, BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(img_ds, BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "syCZJQYr2uBD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contruct Model"
      ],
      "metadata": {
        "id": "SwzOUZzRAnaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.convblock = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.Dropout2d(),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.convblock(x)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_channels=3, init_channels=16, latent_dim=128, img_size=IMG_SIZE):\n",
        "        super(Net, self).__init__()\n",
        "        self.init_channels = init_channels\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder1 = ConvBlock(in_channels, init_channels) # (3, H, W) -> (16, H, W)\n",
        "        self.pooling1 = nn.MaxPool2d(2)\n",
        "        self.encoder2 = ConvBlock(init_channels, init_channels*2) # (16, H/2, W/2) -> (32, H/2, W/2)\n",
        "        self.pooling2 = nn.MaxPool2d(2)\n",
        "        self.encoder3 = ConvBlock(init_channels*2, init_channels*4) # (32, H/4, W/4) -> (64, H/4, W/4)\n",
        "\n",
        "        # bottleneck\n",
        "        self.fc1 = nn.Linear(init_channels*4 * (img_size//4) ** 2, latent_dim)\n",
        "        self.fc2 = nn.Linear(latent_dim, init_channels*4 * (img_size//4) ** 2)\n",
        "\n",
        "        # Decoder\n",
        "        self.upconv2 = nn.ConvTranspose2d(init_channels*4, init_channels*2, kernel_size=2, stride=2) # (64, H/4, W/4) -> (32, H/2, W/2)\n",
        "        self.decoder2 = ConvBlock(init_channels*4, init_channels*2)\n",
        "        self.upconv1 = nn.ConvTranspose2d(init_channels*2, init_channels, kernel_size=2, stride=2) # (32, H/2, W/2) -> (16, H, W)\n",
        "        self.decoder1 = ConvBlock(init_channels*2, init_channels)\n",
        "\n",
        "        # Output\n",
        "        self.output = nn.Conv2d(init_channels, in_channels, kernel_size=1) # (64, H, W) -> (num_classes, H, W)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # Encoder\n",
        "        encode1 = self.encoder1(x)\n",
        "        encode2 = self.encoder2(self.pooling1(encode1))\n",
        "        encode3 = self.encoder3(self.pooling2(encode2))\n",
        "\n",
        "        # Bottleneck\n",
        "        bottleneck = self.fc1(encode3.reshape(encode3.shape[0], -1))\n",
        "        x = self.fc2(bottleneck).reshape(-1, self.init_channels*4, self.img_size//4, self.img_size//4)\n",
        "\n",
        "        # Decoder\n",
        "        x = torch.cat((self.upconv2(x), encode2), dim=1) # (512, H/2, W/2)\n",
        "        x = self.decoder2(x) # (128, H/4, W/4)\n",
        "        x = torch.cat((self.upconv1(x), encode1), dim=1) # (128, H, W)\n",
        "        x = self.decoder1(x) # (64, H, W)\n",
        "        x = self.output(x)\n",
        "\n",
        "        return bottleneck, x"
      ],
      "metadata": {
        "id": "JWnmbmOWPQu_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchsummary\n",
        "\n",
        "model = Net().to(device)\n",
        "torchsummary.summary(model, (3, 32, 32), device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeDrP7hxKw5I",
        "outputId": "623eae67-cf08-4ef8-92c8-7830091c777f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "              ReLU-3           [-1, 16, 32, 32]               0\n",
            "            Conv2d-4           [-1, 16, 32, 32]           2,320\n",
            "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
            "         Dropout2d-6           [-1, 16, 32, 32]               0\n",
            "              ReLU-7           [-1, 16, 32, 32]               0\n",
            "         MaxPool2d-8           [-1, 16, 16, 16]               0\n",
            "            Conv2d-9           [-1, 32, 16, 16]           4,640\n",
            "      BatchNorm2d-10           [-1, 32, 16, 16]              64\n",
            "             ReLU-11           [-1, 32, 16, 16]               0\n",
            "           Conv2d-12           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-13           [-1, 32, 16, 16]              64\n",
            "        Dropout2d-14           [-1, 32, 16, 16]               0\n",
            "             ReLU-15           [-1, 32, 16, 16]               0\n",
            "        MaxPool2d-16             [-1, 32, 8, 8]               0\n",
            "           Conv2d-17             [-1, 64, 8, 8]          18,496\n",
            "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
            "             ReLU-19             [-1, 64, 8, 8]               0\n",
            "           Conv2d-20             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
            "        Dropout2d-22             [-1, 64, 8, 8]               0\n",
            "             ReLU-23             [-1, 64, 8, 8]               0\n",
            "           Linear-24                  [-1, 128]         524,416\n",
            "           Linear-25                 [-1, 4096]         528,384\n",
            "  ConvTranspose2d-26           [-1, 32, 16, 16]           8,224\n",
            "           Conv2d-27           [-1, 32, 16, 16]          18,464\n",
            "      BatchNorm2d-28           [-1, 32, 16, 16]              64\n",
            "             ReLU-29           [-1, 32, 16, 16]               0\n",
            "           Conv2d-30           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-31           [-1, 32, 16, 16]              64\n",
            "        Dropout2d-32           [-1, 32, 16, 16]               0\n",
            "             ReLU-33           [-1, 32, 16, 16]               0\n",
            "  ConvTranspose2d-34           [-1, 16, 32, 32]           2,064\n",
            "           Conv2d-35           [-1, 16, 32, 32]           4,624\n",
            "      BatchNorm2d-36           [-1, 16, 32, 32]              32\n",
            "             ReLU-37           [-1, 16, 32, 32]               0\n",
            "           Conv2d-38           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-39           [-1, 16, 32, 32]              32\n",
            "        Dropout2d-40           [-1, 16, 32, 32]               0\n",
            "             ReLU-41           [-1, 16, 32, 32]               0\n",
            "           Conv2d-42            [-1, 3, 32, 32]              51\n",
            "================================================================\n",
            "Total params: 1,170,515\n",
            "Trainable params: 1,170,515\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.13\n",
            "Params size (MB): 4.47\n",
            "Estimated Total Size (MB): 7.61\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define training and testing process"
      ],
      "metadata": {
        "id": "Bd8F9CApoxYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset) # number of samples\n",
        "    num_batches = len(dataloader) # batches per epoch\n",
        "\n",
        "    model.train() # to training mode.\n",
        "    epoch_loss = 0\n",
        "    for batch_i, (img_aug, img) in enumerate(tqdm(dataloader, leave=False)):\n",
        "        img_aug, img = img_aug.to(device, dtype=torch.float), img.to(device,  dtype=torch.float) # move data to GPU\n",
        "\n",
        "        _, reconsturction = model(img_aug)\n",
        "        loss = loss_fn(reconsturction, img)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # write to logs\n",
        "        epoch_loss += loss.item() # tensor -> python value\n",
        "\n",
        "    # return avg loss of epoch, acc of epoch\n",
        "    return epoch_loss/num_batches\n",
        "\n",
        "\n",
        "def validate(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset) # number of samples\n",
        "    num_batches = len(dataloader) # batches per epoch\n",
        "\n",
        "    model.eval() # model to test mode.\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # No gradient for test data\n",
        "    with torch.no_grad():\n",
        "        for batch_i, (img_aug, img) in enumerate(dataloader):\n",
        "            img_aug, img = img_aug.to(device,  dtype=torch.float), img.to(device,  dtype=torch.float)\n",
        "\n",
        "            _, reconsturction = model(img_aug)\n",
        "            loss = loss_fn(reconsturction, img)\n",
        "\n",
        "            # write to logs\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss/num_batches"
      ],
      "metadata": {
        "id": "zSf1HNhXo1e1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 200\n",
        "\n",
        "model = Net().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "logs = {\n",
        "    'train_loss': [], 'val_loss': []\n",
        "}\n",
        "\n",
        "# early stopping\n",
        "patience = 30\n",
        "counter = 0\n",
        "best_loss = np.inf\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    train_loss = train(train_loader, model, loss_fn, optimizer)\n",
        "    val_loss = validate(val_loader, model, loss_fn)\n",
        "\n",
        "    print(f'EPOCH: {(epoch+1):04d} -> train_loss: {train_loss:.4f} \\ val_loss: {val_loss:.4f}')\n",
        "\n",
        "    logs['train_loss'].append(train_loss)\n",
        "    logs['val_loss'].append(val_loss)\n",
        "\n",
        "    # if epoch % 10 == 0:\n",
        "    #     torch.save(model.state_dict(), f'DL_hw2_epoch{epoch+1}_model.pth')\n",
        "    # chcek improvement\n",
        "    if val_loss <  best_loss:\n",
        "        counter = 0\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/NTU_ML/Hw3/ckpt/best_model.pth')\n",
        "        print('-------------------- Model Save --------------------')\n",
        "    else:\n",
        "        counter += 1\n",
        "    if counter >= patience:\n",
        "        print('-------------------- Early Stop --------------------')\n",
        "        break"
      ],
      "metadata": {
        "id": "a5p_wNywt9JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clustering(model, device, loader, n_iter, reduced_method, reduced_dim, perplexity):\n",
        "    assert reduced_method in ['pca', 'tsne', None]\n",
        "\n",
        "    model.eval()\n",
        "    latent_vec = torch.tensor([]).to(device, dtype=torch.float)\n",
        "    for idx, (image_aug, image) in enumerate(loader):\n",
        "        print(\"predict %d / %d\" % (idx, len(loader)) , end='\\r')\n",
        "        image = image.to(device, dtype=torch.float)\n",
        "        latent, r = model(image)\n",
        "        latent_vec = torch.cat((latent_vec, latent), dim=0)\n",
        "\n",
        "    latent_vec = latent_vec.cpu().detach().numpy()\n",
        "\n",
        "    if reduced_method == 'tsne':\n",
        "        tsne = TSNE(n_components=reduced_dim, verbose=1, method='exact', perplexity=perplexity, n_iter=n_iter)\n",
        "        latent_vec = tsne.fit_transform(latent_vec)\n",
        "    elif reduced_method == 'pca':\n",
        "        pca = PCA(n_components=reduced_dim, copy=False, whiten=True, svd_solver='full')\n",
        "        latent_vec = pca.fit_transform(latent_vec)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=2, random_state=0, max_iter=n_iter).fit(latent_vec)\n",
        "    return kmeans.labels_"
      ],
      "metadata": {
        "id": "FPijW5xstnQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_output(predict_result, file_name='predict.csv'):\n",
        "    with open(file_name, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['id', 'label'])\n",
        "        for i in range(len(predict_result)):\n",
        "            writer.writerow([str(i), str(predict_result[i])])"
      ],
      "metadata": {
        "id": "V6Uc0lagtz4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "predicted = clustering(model, device, test_loader, 1500, reduced_method='tsne', reduced_dim=2, perplexity=15)\n",
        "write_output(predicted, 'pred.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDht2dQGt1VI",
        "outputId": "f8402260-e7d1-4a59-ccfa-392b75bab8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[t-SNE] Computing pairwise distances...\n",
            "[t-SNE] Computed conditional probabilities for sample 1000 / 9000\n",
            "[t-SNE] Computed conditional probabilities for sample 2000 / 9000\n",
            "[t-SNE] Computed conditional probabilities for sample 3000 / 9000\n",
            "[t-SNE] Computed conditional probabilities for sample 4000 / 9000\n",
            "[t-SNE] Computed conditional probabilities for sample 5000 / 9000\n",
            "[t-SNE] Computed conditional probabilities for sample 6000 / 9000\n",
            "[t-SNE] Computed conditional probabilities for sample 7000 / 9000\n",
            "[t-SNE] Computed conditional probabilities for sample 8000 / 9000\n",
            "[t-SNE] Computed conditional probabilities for sample 9000 / 9000\n",
            "[t-SNE] Mean sigma: 2.065020\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 95.070753\n"
          ]
        }
      ]
    }
  ]
}